# -*- coding: utf-8 -*-
"""FakeNewsDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nBC0vhtInhjxaizsOHGsoIQUN7ud_GXa
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
    import numpy as np
    import pandas as pd
    import itertools
    from sklearn.model_selection import train_test_split
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.linear_model import PassiveAggressiveClassifier
    from sklearn.metrics import accuracy_score, confusion_matrix
    import matplotlib.pyplot as plt
    from collections import Counter
   
    #from sklearn import naive_bayes, metrics, svm
    from IPython.display import Image
    import warnings
    warnings.filterwarnings("ignore")
#     %matplotlib inline

df = pd.read_csv('/content/news.csv')
X=df['text']
y=df['label']

print(X)

print(y)

y.value_counts()

df.shape

df.head()

count_Class=pd.value_counts(df["label"], sort= True)
count_Class.plot(kind= 'bar', color= ["blue", "orange"])
plt.title('Bar chart')
plt.show()

count_Class.plot(kind = 'pie',  autopct='%1.0f%%')
plt.title('Pie chart')
plt.ylabel('')
plt.show()

count1 = Counter(" ".join(df[df['label']=='REAL']["text"]).split()).most_common(20)
df1 = pd.DataFrame.from_dict(count1)
df1 = df1.rename(columns={0: "words in REAL", 1 : "count"})
count2 = Counter(" ".join(df[df['label']=='FAKE']["text"]).split()).most_common(20)
df2 = pd.DataFrame.from_dict(count2)
df2 = df2.rename(columns={0: "words in FAKE", 1 : "count_"})

df1.plot.bar(legend = False)
y_pos = np.arange(len(df1["words in REAL"]))
plt.xticks(y_pos, df1["words in REAL"])
plt.title('More frequent words in non-spam messages')
plt.xlabel('words')
plt.ylabel('number')
plt.show()

df2.plot.bar(legend = False, color = 'orange')
y_pos = np.arange(len(df2["words in FAKE"]))
plt.xticks(y_pos, df2["words in FAKE"])
plt.title('More frequent words in spam messages')
plt.xlabel('words')
plt.ylabel('number')
plt.show()

from sklearn.model_selection import train_test_split

X = df['text'] 
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()

X_train_tfidf = vectorizer.fit_transform(X_train) # remember to use the original X_train set
X_train_tfidf.shape

from sklearn.svm import LinearSVC
clf = LinearSVC()
clf.fit(X_train_tfidf,y_train)

from sklearn.pipeline import Pipeline
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.svm import LinearSVC

text_clf = Pipeline([('tfidf', TfidfVectorizer()),
                     ('clf', LinearSVC()),
])

# Feed the training data through the pipeline
text_clf.fit(X_train, y_train)

predictions = text_clf.predict(X_test)
from sklearn import metrics
print(metrics.confusion_matrix(y_test,predictions))

print(metrics.classification_report(y_test,predictions))

X_train_tfidf1 = vectorizer.fit_transform(["your email was selected to claim to sum of  $ 5,000,000 in the 2011 european lottery"])
X_train_tfidf1.shape

predi = text_clf.predict(["your email was selected to claim to sum of  $ 5,000,000 in the 2011 european lottery"])
print(predi)

predict=text_clf.predict(["India's Covid-19 caseload has crossed the 8.5 lakh mark. The rapid spread of the pandemic has seen the country's share in daily global cases rise to 12%. Late last night, actor Amitabh Bachchan, son Abhishek tested positive for Covid-19 and were hospitalised. Their residence 'Jalsa' has now been declared a containment zone."])
print(predict)

predi = text_clf.predict(["Amid reports that the Congress was faced with a crisis over the survival of its government in Rajasthan, state Tourism Minister Vishvendra Singh on Sunday said he was visiting Delhi over a personal matter."])
print(predi)

predi = text_clf.predict(["Breaking news live updates: 1 BSF personnel arrested by Punjab police in a drug smuggling case"])
print(predi)

predi = text_clf.predict(["your email was selected to claim to sum of  $ 5,000,000 in the 2011 european lottery"])
print(predi)